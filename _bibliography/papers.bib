---
---

@string{aps = {American Physical Society,}}

@article{2024_Simon,
  title={Mathematical capabilities of Chat{GPT}},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp and Berner, Julius},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024},
  abstract = {We investigate the mathematical capabilities of two versions of ChatGPT (released 9-January-2023 and 30-January-2023) and of GPT-4 by testing them on publicly available datasets, as well as hand-crafted ones, using a novel evaluation scheme. In contrast to formal mathematics, where large databases of formal proofs are available (e.g., mathlib, the Lean Mathematical Library), current datasets of natural-language mathematics used to benchmark language models either cover only elementary mathematics or are very small. We address this by publicly releasing two new datasets: GHOSTS and miniGHOSTS. These are the first natural-language datasets curated by working researchers in mathematics that (1) aim to cover graduate-level mathematics, (2) provide a holistic overview of the mathematical capabilities of language models, and (3) distinguish multiple dimensions of mathematical reasoning. These datasets test, by using 1636 human expert evaluations, whether ChatGPT and GPT-4 can be helpful assistants to professional mathematicians by emulating use cases that arise in the daily professional activities of mathematicians. We benchmark the models on a range of fine-grained performance metrics. For advanced mathematics, this is the most detailed evaluation effort to date. We find that ChatGPT and GPT-4 can be used most successfully as mathematical assistants for querying facts, acting as mathematical search engines and knowledge base interfaces. GPT-4 can additionally be used for undergraduate-level mathematics but fails on graduate-level difficulty. Contrary to many positive reports in the media about GPT-4 and ChatGPT's exam-solving abilities (a potential case of selection bias), their overall mathematical performance is well below the level of a graduate student. Hence, if you aim to use ChatGPT to pass a graduate-level math exam, you would be better off copying from your average peer!},
  booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
  google_scholar_id={j8SEvjWlNXcC},
  selected={true},
  html={https://proceedings.neurips.cc/paper_files/paper/2023/hash/58168e8a92994655d6da3939e7cc0918-Abstract-Datasets_and_Benchmarks.html},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/file/58168e8a92994655d6da3939e7cc0918-Paper-Datasets_and_Benchmarks.pdf},
  dimensions={true},
  doi={10.48550/arXiv.2301.13867},
  pdf={1.pdf},
  bibtex_show={true}
}

@article{2020_Griffiths,
  title={Constrained {Bayesian} optimization for automatic chemical design using variational autoencoders},
  author={Griffiths, Ryan-Rhys and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel},
  journal={Chemical Science},
  volume={11},
  number={2},
  pages={577--586},
  year={2020},
  publisher={Royal Society of Chemistry},
  google_scholar_id={08ZZubdj9fEC},
  altmetric={74748143},
  doi={10.1039/C9SC04026A},
  html={https://pubs.rsc.org/en/content/articlehtml/2019/sc/c9sc04026a},
  url={https://pubs.rsc.org/en/content/articlepdf/2020/sc/c9sc04026a},
  bibtex_show={true},
  dimensions={true},
  pdf={2.pdf},
  abstract={Automatic Chemical Design is a framework for generating novel molecules with optimized properties. The original scheme, featuring Bayesian optimization over the latent space of a variational autoencoder, suffers from the pathology that it tends to produce invalid molecular structures. First, we demonstrate empirically that this pathology arises when the Bayesian optimization scheme queries latent space points far away from the data on which the variational autoencoder has been trained. Secondly, by reformulating the search procedure as a constrained Bayesian optimization problem, we show that the effects of this pathology can be mitigated, yielding marked improvements in the validity of the generated molecules. We posit that constrained Bayesian optimization is a good approach for solving this kind of training set mismatch in many generative tasks involving Bayesian optimization over the latent space of a variational autoencoder.}
}

@article{2022_Cowen,
  title={{HEBO}: Pushing the limits of sample-efficient hyper-parameter optimisation},
  author={Cowen-Rivers, Alexander I and Lyu, Wenlong and Tutunov, Rasul and Wang, Zhi and Grosnit, Antoine and Griffiths, Ryan Rhys and Maraval, Alexandre Max and Jianye, Hao and Wang, Jun and Peters, Jan and others},
  journal={Journal of Artificial Intelligence Research},
  abstract = {In this work we rigorously analyse assumptions inherent to black-box optimisation hyper-parameter tuning tasks. Our results on the Bayesmark benchmark indicate that heteroscedasticity and non-stationarity pose significant challenges for black-box optimisers. Based on these findings, we propose a Heteroscedastic and Evolutionary Bayesian Optimisation solver (HEBO). HEBO performs non-linear input and output warping, admits exact marginal log-likelihood optimisation and is robust to the values of learned parameters. We demonstrate HEBO’s empirical efficacy on the NeurIPS 2020 Black-Box Optimisation challenge, where HEBO placed first. Upon further analysis, we observe that HEBO significantly outperforms existing black-box optimisers on 108 machine learning hyperparameter tuning tasks comprising the Bayesmark benchmark. Our findings indicate that the majority of hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity, multiobjective acquisition ensembles with Pareto front solutions improve queried configurations, and robust acquisition maximisers afford empirical advantages relative to their non-robust counterparts. We hope these findings may serve as guiding principles for practitioners of Bayesian optimisation.},
  volume={74},
  pages={1269--1349},
  year={2022},
  google_scholar_id={u9iWguZQMMsC},
  altmetric={131273813},
  selected={true},
  pdf={3.pdf},
  url={https://www.jair.org/index.php/jair/article/view/13643},
  html={https://www.jair.org/index.php/jair/article/view/13643},
  doi={10.1613/jair.1.13643},
  bibtex_show={true},
  dimensions={true}
}

@article{2020_Cheng,
  title={Mapping materials and molecules},
  author={Cheng, Bingqing and Griffiths, Ryan-Rhys and Wengert, Simon and Kunkel, Christian and Stenczel, Tamas and Zhu, Bonan and Deringer, Volker L and Bernstein, Noam and Margraf, Johannes T and Reuter, Karsten and others},
  journal={Accounts of Chemical Research},
  volume={53},
  number={9},
  pages={1981--1991},
  year={2020},
  publisher={ACS Publications},
  google_scholar_id={8k81kl-MbHgC},
  altmetric={88298270},
  doi={10.1021/acs.accounts.0c00403},
  bibtex_show={true},
  dimensions={true},
  url={https://pubs.acs.org/doi/abs/10.1021/acs.accounts.0c00403},
  html={https://pubs.acs.org/doi/abs/10.1021/acs.accounts.0c00403},
  abstract={The visualization of data is indispensable in scientific research, from the early stages when human insight forms to the final step of communicating results. In computational physics, chemistry and materials science, it can be as simple as making a scatter plot or as straightforward as looking through the snapshots of atomic positions manually. However, as a result of the “big data” revolution, these conventional approaches are often inadequate. The widespread adoption of high-throughput computation for materials discovery and the associated community-wide repositories have given rise to data sets that contain an enormous number of compounds and atomic configurations. A typical data set contains thousands to millions of atomic structures, along with a diverse range of properties such as formation energies, band gaps, or bioactivities.It would thus be desirable to have a data-driven and automated framework for visualizing and analyzing such structural data sets. The key idea is to construct a low-dimensional representation of the data, which facilitates navigation, reveals underlying patterns, and helps to identify data points with unusual attributes. Such data-intensive maps, often employing machine learning methods, are appearing more and more frequently in the literature. However, to the wider community, it is not always transparent how these maps are made and how they should be interpreted. Furthermore, while these maps undoubtedly serve a decorative purpose in academic publications, it is not always apparent what extra information can be garnered from reading or making them.This Account attempts to answer such questions. We start with a concise summary of the theory of representing chemical environments, followed by the introduction of a simple yet practical conceptual approach for generating structure maps in a generic and automated manner. Such analysis and mapping is made nearly effortless by employing the newly developed software tool ASAP. To showcase the applicability to a wide variety of systems in chemistry and materials science, we provide several illustrative examples, including crystalline and amorphous materials, interfaces, and organic molecules. In these examples, the maps not only help to sift through large data sets but also reveal hidden patterns that could be easily missed using conventional analyses.The explosion in the amount of computed information in chemistry and materials science has made visualization into a science in itself. Not only have we benefited from exploiting these visualization methods in previous works, we also believe that the automated mapping of data sets will in turn stimulate further creativity and exploration, as well as ultimately feed back into future advances in the respective fields. }
}

@article{2021_Grosnit,
  title={High-dimensional {Bayesian} optimisation with variational autoencoders and deep metric learning},
  author={Grosnit, Antoine and Tutunov, Rasul and Maraval, Alexandre Max and Griffiths, Ryan-Rhys and Cowen-Rivers, Alexander I and Yang, Lin and Zhu, Lin and Lyu, Wenlong and Chen, Zhitang and Wang, Jun and others},
  journal={arXiv preprint arXiv:2106.03609},
  year={2021},
  google_scholar_id={L8Ckcad2t8MC},
  bibtex_show={true},
  dimensions={true},
  url={https://arxiv.org/abs/2106.03609},
  html={https://arxiv.org/abs/2106.03609},
  pdf={5.pdf},
  abstract={We introduce a method combining variational autoencoders (VAEs) and deep metric learning to perform Bayesian optimisation (BO) over high-dimensional and structured input spaces. By adapting ideas from deep metric learning, we use label guidance from the blackbox function to structure the VAE latent space, facilitating the Gaussian process fit and yielding improved BO performance. Importantly for BO problem settings, our method operates in semi-supervised regimes where only few labelled data points are available. We run experiments on three real-world tasks, achieving state-of-the-art results on the penalised logP molecule generation benchmark using just 3% of the labelled data required by previous approaches. As a theoretical contribution, we present a proof of vanishing regret for VAE BO.}
}

@article{2024_gauche,
  title={{GAUCHE}: a library for {Gaussian} processes in chemistry},
  author={Griffiths, Ryan-Rhys and Klarner, Leo and Moss, Henry and Ravuri, Aditya and Truong, Sang and Du, Yuanqi and Stanton, Samuel and Tom, Gary and Rankovic, Bojana and Jamasb, Arian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024},
  pdf={6.pdf},
  google_scholar_id={uJ-U7cs_P_0C},
  bibtex_show={true},
  dimensions={true},
  html={https://proceedings.neurips.cc/paper_files/paper/2023/hash/f2b1b2e974fa5ea622dd87f22815f423-Abstract-Conference.html},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/f2b1b2e974fa5ea622dd87f22815f423-Paper-Conference.pdf},
  abstract={We introduce GAUCHE, an open-source library for GAUssian processes in CHEmistry. Gaussian processes have long been a cornerstone of probabilistic machine learning, affording particular advantages for uncertainty quantification and Bayesian optimisation. Extending Gaussian processes to molecular representations, however, necessitates kernels defined over structured inputs such as graphs, strings and bit vectors. By providing such kernels in a modular, robust and easy-to-use framework, we seek to enable expert chemists and materials scientists to make use of state-of-the-art black-box optimization techniques. Motivated by scenarios frequently encountered in practice, we showcase applications for GAUCHE in molecular discovery, chemical reaction optimisation and protein design. The codebase is made available at https://github.com/leojklarner/gauche.}
}

@article{2022_Griffiths,
  title={Data-driven discovery of molecular photoswitches with multioutput {Gaussian} processes},
  author={Griffiths, Ryan-Rhys and Greenfield, Jake L and Thawani, Aditya R and Jamasb, Arian R and Moss, Henry B and Bourached, Anthony and Jones, Penelope and McCorkindale, William and Aldrick, Alexander A and Fuchter, Matthew J and others},
  journal={Chemical Science},
  volume={13},
  number={45},
  pages={13541--13551},
  year={2022},
  pdf={7.pdf},
  publisher={Royal Society of Chemistry},
  google_scholar_id={UxriW0iASnsC},
  html={https://pubs.rsc.org/en/content/articlehtml/2022/sc/d2sc04306h},
  url={https://pubs.rsc.org/en/content/articlehtml/2022/sc/d2sc04306h},
  doi={10.1039/D2SC04306H},
  dimensions={true},
  bibtex_show={true},
  altmetric={138309393},
  abstract={Photoswitchable molecules display two or more isomeric forms that may be accessed using light. Separating the electronic absorption bands of these isomers is key to selectively addressing a specific isomer and achieving high photostationary states whilst overall red-shifting the absorption bands serves to limit material damage due to UV-exposure and increases penetration depth in photopharmacological applications. Engineering these properties into a system through synthetic design however, remains a challenge. Here, we present a data-driven discovery pipeline for molecular photoswitches underpinned by dataset curation and multitask learning with Gaussian processes. In the prediction of electronic transition wavelengths, we demonstrate that a multioutput Gaussian process (MOGP) trained using labels from four photoswitch transition wavelengths yields the strongest predictive performance relative to single-task models as well as operationally outperforming time-dependent density functional theory (TD-DFT) in terms of the wall-clock time for prediction. We validate our proposed approach experimentally by screening a library of commercially available photoswitchable molecules. Through this screen, we identified several motifs that displayed separated electronic absorption bands of their isomers, exhibited red-shifted absorptions, and are suited for information transfer and photopharmacological applications. Our curated dataset, code, as well as all models are made available at https://github.com/Ryan-Rhys/The-Photoswitch-Dataset.}
}

@article{2021_Griffiths,
  title={Achieving robustness to aleatoric uncertainty with heteroscedastic {Bayesian} optimisation},
  author={Griffiths, Ryan-Rhys and Aldrick, Alexander A and Garcia-Ortegon, Miguel and Lalchand, Vidhi and others},
  journal={Machine Learning: Science and Technology},
  volume={3},
  number={1},
  pages={015004},
  year={2021},
  pdf={8.pdf},
  publisher={IOP Publishing},
  google_scholar_id={M05iB0D1s5AC},
  url={https://iopscience.iop.org/article/10.1088/2632-2153/ac298c/meta},
  doi={10.1088/2632-2153/ac298c},
  dimensions={true},
  bibtex_show={true},
  altmetric={68879641},
  abstract={Bayesian optimisation is a sample-efficient search methodology that holds great promise for accelerating drug and materials discovery programs. A frequently-overlooked modelling consideration in Bayesian optimisation strategies however, is the representation of heteroscedastic aleatoric uncertainty. In many practical applications it is desirable to identify inputs with low aleatoric noise, an example of which might be a material composition which displays robust properties in response to a noisy fabrication process. In this paper, we propose a heteroscedastic Bayesian optimisation scheme capable of representing and minimising aleatoric noise across the input space. Our scheme employs a heteroscedastic Gaussian process surrogate model in conjunction with two straightforward adaptations of existing acquisition functions. First, we extend the augmented expected improvement heuristic to the heteroscedastic setting and second, we introduce the aleatoric noise-penalised expected improvement (ANPEI) heuristic. Both methodologies are capable of penalising aleatoric noise in the suggestions. In particular, the ANPEI acquisition yields improved performance relative to homoscedastic Bayesian optimisation and random sampling on toy problems as well as on two real-world scientific datasets. Code is available at: https://github.com/Ryan-Rhys/Heteroscedastic-BO}
}

@article{2020_Moss,
  title={Gaussian process molecule property prediction with {FlowMO}},
  author={Moss, Henry B and Griffiths, Ryan-Rhys},
  journal={arXiv preprint arXiv:2010.01118},
  year={2020},
  pdf={9.pdf},
  dimensions={true},
  bibtex_show={true},
  google_scholar_id={MXK_kJrjxJIC},
  url={https://arxiv.org/abs/2010.01118},
  html={https://arxiv.org/abs/2010.01118},
  abstract={We present FlowMO: an open-source Python library for molecular property prediction with Gaussian Processes. Built upon GPflow and RDKit, FlowMO enables the user to make predictions with well-calibrated uncertainty estimates, an output central to active learning and molecular design applications. Gaussian Processes are particularly attractive for modelling small molecular datasets, a characteristic of many real-world virtual screening campaigns where high-quality experimental data is scarce. Computational experiments across three small datasets demonstrate comparable predictive performance to deep learning methods but with superior uncertainty calibration.}
}

@article{2021_Bourached,
  title={Recovery of underdrawings and ghost-paintings via style transfer by deep convolutional neural networks: A digital tool for art scholars},
  author={Bourached, Anthony and Cann, George H and Griffths, Ryan-Rhys and Stork, David G},
  journal={Electronic Imaging},
  volume={33},
  pages={1--10},
  pdf={10.pdf},
  year={2021},
  publisher={Society for Imaging Science and Technology},
  bibtex_show={true},
  dimensions={true},
  google_scholar_id={M3ejUd6NZC8C},
  doi={10.2352/ISSN.2470-1173.2021.14.CVAA-042},
  url={https://library.imaging.org/ei/articles/33/14/art00006},
  html={https://library.imaging.org/ei/articles/33/14/art00006},
  abstract={We describe the application of convolutional neural network style transfer to the problem of improved visualization of underdrawings and ghost-paintings in fine art oil paintings. Such underdrawings and hidden paintings are typically revealed by x-ray or infrared techniques which yield images that are grayscale, and thus devoid of color and full style information. Past methods for inferring color in underdrawings have been based on physical x-ray uorescence spectral imaging of pigments in ghost-paintings and are thus expensive, time consuming, and require equipment not available in most conservation studios. Our algorithmic methods do not need such expensive physical imaging devices. Our proof-ofconcept system, applied to works by Pablo Picasso and Leonardo, reveal colors and designs that respect the natural segmentation in the ghost-painting. We believe the computed images provide insight into the artist and associated oeuvre not available by other means. Our results strongly suggest that future applications based on larger corpora of paintings for training will display color schemes and designs that even more closely resemble works of the artist. For these reasons refinements to our methods should find wide use in art conservation, connoisseurship, and art analysis.}
}

@article{2021_mrk,
  title={Modeling the multiwavelength variability of {Mrk} 335 using {Gaussian} processes},
  author={Griffiths, Ryan-Rhys and Jiang, Jiachen and Buisson, Douglas JK and Wilkins, Dan and Gallo, Luigi C and Ingram, Adam and Grupe, Dirk and Kara, Erin and Parker, Michael L and Alston, William and others},
  journal={The Astrophysical Journal},
  volume={914},
  number={2},
  pages={144},
  pdf={11.pdf},
  year={2021},
  publisher={IOP Publishing},
  google_scholar_id={blknAaTinKkC},
  html={https://iopscience.iop.org/article/10.3847/1538-4357/abfa9f/meta},
  url={https://iopscience.iop.org/article/10.3847/1538-4357/abfa9f/meta},
  doi={10.3847/1538-4357/abfa9f},
  altmetric={101653867},
  dimensions={true},
  bibtex_show={true},
  inspirehep_id={1851189},
  abstract={The optical and UV variability of the majority of active galactic nuclei may be related to the reprocessing of rapidly changing X-ray emission from a more compact region near the central black hole. Such a reprocessing model would be characterized by lags between X-ray and optical/UV emission due to differences in light travel time. Observationally, however, such lag features have been difficult to detect due to gaps in the lightcurves introduced through factors such as source visibility or limited telescope time. In this work, Gaussian process regression is employed to interpolate the gaps in the Swift X-ray and UV lightcurves of the narrow-line Seyfert 1 galaxy Mrk 335. In a simulation study of five commonly employed analytic Gaussian process kernels, we conclude that the Matern  and rational quadratic kernels yield the most well-specified models for the X-ray and UVW2 bands of Mrk 335. In analyzing the structure functions of the Gaussian process lightcurves, we obtain a broken power law with a break point at 125 days in the UVW2 band. In the X-ray band, the structure function of the Gaussian process lightcurve is consistent with a power law in the case of the rational quadratic kernel while a broken power law with a break point at 66 days is obtained from the Matern  kernel. The subsequent cross-correlation analysis is consistent with previous studies and furthermore shows tentative evidence for a broad X-ray-UV lag feature of up to 30 days in the lag-frequency spectrum where the significance of the lag depends on the choice of Gaussian process kernel.}
}

@article{2022_Bourached,
  title={Generative model-enhanced human motion prediction},
  author={Bourached, Anthony and Griffiths, Ryan-Rhys and Gray, Robert and Jha, Ashwani and Nachev, Parashkev},
  journal={Applied AI Letters},
  volume={3},
  number={2},
  pages={e63},
  pdf={12.pdf},
  year={2022},
  publisher={Wiley Online Library},
  google_scholar_id={08ZZubdj9fEC},
  doi={10.1002/ail2.63},
  altmetric={121086886},
  bibtex_show={true},
  dimensions={true},
  url={https://onlinelibrary.wiley.com/doi/full/10.1002/ail2.63},
  html={https://onlinelibrary.wiley.com/doi/full/10.1002/ail2.63},
  abstract={The task of predicting human motion is complicated by the natural heterogeneity and compositionality of actions, necessitating robustness to distributional shifts as far as out-of-distribution (OoD). Here, we formulate a new OoD benchmark based on the Human3.6M and Carnegie Mellon University (CMU) motion capture datasets, and introduce a hybrid framework for hardening discriminative architectures to OoD failure by augmenting them with a generative model. When applied to current state-of-the-art discriminative models, we show that the proposed approach improves OoD robustness without sacrificing in-distribution performance, and can theoretically facilitate model interpretability. We suggest human motion predictors ought to be constructed with OoD challenges in mind, and provide an extensible general framework for hardening diverse discriminative architectures to extreme distributional shift. The code is available at: https://github.com/bouracha/OoDMotion.}
}

@article{2021_Aziz,
  title={Data considerations in graph representation learning for supply chain networks},
  author={Aziz, Ajmal and Kosasih, Edward Elson and Griffiths, Ryan-Rhys and Brintrup, Alexandra},
  journal={arXiv preprint arXiv:2107.10609},
  year={2021},
  pdf={13.pdf},
  bibtex_show={true},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC},
  url={https://arxiv.org/abs/2107.10609},
  html={https://arxiv.org/abs/2107.10609},
  abstract={Supply chain network data is a valuable asset for businesses wishing to understand their ethical profile, security of supply, and efficiency. Possession of a dataset alone however is not a sufficient enabler of actionable decisions due to incomplete information. In this paper, we present a graph representation learning approach to uncover hidden dependency links that focal companies may not be aware of. To the best of our knowledge, our work is the first to represent a supply chain as a heterogeneous knowledge graph with learnable embeddings. We demonstrate that our representation facilitates state-of-the-art performance on link prediction of a global automotive supply chain network using a relational graph convolutional network. It is anticipated that our method will be directly applicable to businesses wishing to sever links with nefarious entities and mitigate risk of supply failure. More abstractly, it is anticipated that our method will be useful to inform representation learning of supply chain networks for downstream tasks beyond link prediction.}
}

@article{2021_Bias,
  title={Dataset bias in the natural sciences: a case study in chemical reaction prediction and synthesis design},
  author={Griffiths, Ryan-Rhys and Schwaller, Philippe and Lee, Alpha A},
  journal={arXiv preprint arXiv:2105.02637},
  year={2021},
  pdf={14.pdf},
  google_scholar_id={08ZZubdj9fEC},
  bibtex_show={true},
  dimensions={true},
  inspirehep_id={1991797},
  url={https://arxiv.org/abs/2105.02637},
  html={https://arxiv.org/abs/2105.02637},
  abstract={Datasets in the Natural Sciences are often curated with the goal of aiding scientific understanding and hence may not always be in a form that facilitates the application of machine learning. In this paper, we identify three trends within the fields of chemical reaction prediction and synthesis design that require a change in direction. First, the manner in which reaction datasets are split into reactants and reagents encourages testing models in an unrealistically generous manner. Second, we highlight the prevalence of mislabelled data, and suggest that the focus should be on outlier removal rather than data fitting only. Lastly, we discuss the problem of reagent prediction, in addition to reactant prediction, in order to solve the full synthesis design problem, highlighting the mismatch between what machine learning solves and what a lab chemist would need. Our critiques are also relevant to the burgeoning field of using machine learning to accelerate progress in experimental Natural Sciences, where datasets are often split in a biased way, are highly noisy, and contextual variables that are not evident from the data strongly influence the outcome of experiments.}
}

@inproceedings{2019_Grant,
  title={Adaptive sensor placement for continuous spaces},
  author={Grant, James and Boukouvalas, Alexis and Griffiths, Ryan-Rhys and Leslie, David and Vakili, Sattar and De Cote, Enrique Munoz},
  booktitle={International Conference on Machine Learning},
  pages={2385--2393},
  year={2019},
  pdf={15.pdf},
  organization={PMLR},
  google_scholar_id={08ZZubdj9fEC},
  bibtex_show={true},
  dimensions={true},
  html={https://proceedings.mlr.press/v97/grant19a.html},
  url={https://proceedings.mlr.press/v97/grant19a.html},
  abstract={We consider the problem of adaptively placing sensors along an interval to detect stochastically-generated events. We present a new formulation of the problem as a continuum-armed bandit problem with feedback in the form of partial observations of realisations of an inhomogeneous Poisson process. We design a solution method by combining Thompson sampling with nonparametric inference via increasingly granular Bayesian histograms and derive an $\tilde{O}(T^{2/3})$ bound on the Bayesian regret in $T$ rounds. This is coupled with the design of an efficent optimisation approach to select actions in polynomial time. In simulations we demonstrate our approach to have substantially lower and less variable regret than competitor algorithms.}
}

@article{2021_Grosnit,
  title={Are we forgetting about compositional optimisers in {Bayesian} optimisation?},
  author={Grosnit, Antoine and Cowen-Rivers, Alexander I and Tutunov, Rasul and Griffiths, Ryan-Rhys and Wang, Jun and Bou-Ammar, Haitham},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={160},
  pdf={16.pdf},
  pages={1--78},
  year={2021},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC},
  html={https://www.jmlr.org/papers/v22/20-1422.html},
  bibtex_show={true},
  url={http://jmlr.org/papers/v22/20-1422.html},
  doi={10.48550/arXiv.2012.08240},
  abstract={Bayesian optimisation presents a sample-efficient methodology for global optimisation. Within this framework, a crucial performance-determining subroutine is the maximisation of the acquisition function, a task complicated by the fact that acquisition functions tend to be non-convex and thus nontrivial to optimise. In this paper, we undertake a comprehensive empirical study of approaches to maximise the acquisition function. Additionally, by deriving novel, yet mathematically equivalent, compositional forms for popular acquisition functions, we recast the maximisation task as a compositional optimisation problem, allowing us to benefit from the extensive literature in this field. We highlight the empirical advantages of the compositional approach to acquisition function maximisation across 3958 individual experiments comprising synthetic optimisation tasks as well as tasks from Bayesmark. Given the generality of the acquisition function maximisation subroutine, we posit that the adoption of compositional optimisers has the potential to yield performance improvements across all domains in which Bayesian optimisation is currently being applied.}
}

@article{2024_Rankovic,
  title={Bayesian optimisation for additive screening and yield improvements--beyond one-hot encoding},
  author={Rankovi{\'c}, Bojana and Griffiths, Ryan-Rhys and Moss, Henry B and Schwaller, Philippe},
  journal={Digital Discovery},
  volume={3},
  number={4},
  pdf={17.pdf},
  pages={654--666},
  year={2024},
  publisher={Royal Society of Chemistry},
  google_scholar_id={08ZZubdj9fEC},
  html={https://pubs.rsc.org/en/content/articlehtml/2024/dd/d3dd00096f},
  doi={10.1039/D3DD00096F},
  altmetric={156228291},
  bibtex_show={true},
  dimensions={true}
}

@article{2021_Stork,
  title={Computational identification of significant actors in paintings through symbols and attributes},
  author={Stork, David G and Bourached, Anthony and Cann, George H and Griffths, Ryan-Rhys},
  journal={Electronic Imaging},
  volume={33},
  pages={1--8},
  year={2021},
  pdf={18.pdf},
  publisher={Society for Imaging Science and Technology},
  bibtex_show={true},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2021_Cann,
  title={Resolution enhancement in the recovery of underdrawings via style transfer by generative adversarial deep neural networks},
  author={Cann, George H and Bourached, Anthony and Griffths, Ryan-Rhys and Stork, David G},
  journal={Electronic Imaging},
  volume={33},
  pages={1--8},
  year={2021},
  pdf={19.pdf},
  publisher={Society for Imaging Science and Technology},
  bibtex_show={true},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC}
}

@inproceedings{2022_Verma,
  title={High-dimensional {Bayesian} optimization with invariance},
  author={Verma, Ekansh and Chakraborty, Souradip and Griffiths, Ryan-Rhys},
  booktitle={ICML Workshop on Adaptive Experimental Design and Active Learning},
  year={2022},
  bibtex_show={true},
  pdf={20.pdf},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2022_Kell,
  title={Extracting associations and meanings of objects depicted in artworks through bi-modal deep networks},
  author={Kell, Gregory and Griffiths, Ryan-Rhys and Bourached, Anthony and Stork, David G},
  journal={Electronic Imaging},
  volume={34},
  pages={1--14},
  year={2022},
  pdf={21.pdf},
  publisher={Society for Imaging Science and Technology},
  bibtex_show={true},
  dimensions={true},
  google_scholar_id={08ZZubdj9fEC}
}

@phdthesis{2023_Griffiths,
  title={Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes},
  author={Griffiths, Ryan-Rhys},
  year={2023},
  school={University of Cambridge},
  google_scholar_id={08ZZubdj9fEC},
  doi={10.17863/CAM.93643},
  altmetric={144506162},
  pdf={22.pdf},
  inspirehep_id={2646233},
  bibtex_show={true},
  dimensions={true}
}

@article{2020_Zagar,
  title={On the voltage-controlled assembly of nanoparticle arrays at electrochemical solid/liquid interfaces},
  author={Zagar, Cristian and Griffiths, Ryan-Rhys and Podgornik, Rudolf and Kornyshev, Alexei A},
  journal={Journal of Electroanalytical Chemistry},
  volume={872},
  pages={114275},
  year={2020},
  publisher={Elsevier},
  google_scholar_id={08ZZubdj9fEC},
  doi={10.1016/j.jelechem.2020.114275},
  url={https://www.sciencedirect.com/science/article/abs/pii/S1572665720305038},
  altmetric={90950147},
  bibtex_show={true},
  dimensions={true}
}

@article{2021_jha,
  title={Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion},
  author={Bourached, Anthony and Gray, Robert and Guan, Xiaodong and Griffiths, Ryan-Rhys and Jha, Ashwani and Nachev, Parashkev},
  journal={arXiv preprint arXiv:2111.12602},
  year={2021},
  bibtex_show={true},
  dimensions={true},
  pdf={24.pdf},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2024_Gowers,
  title={Data for mathematical copilots: Better ways of presenting proofs for machine learning},
  author={Frieder, Simon and Bayer, Jonas and Collins, Katherine M and Berner, Julius and Loader, Jacob and Juh{\'a}sz, Andr{\'a}s and Ruehle, Fabian and Welleck, Sean and Poesia, Gabriel and Griffiths, Ryan-Rhys and others},
  journal={arXiv preprint arXiv:2412.15184},
  year={2024},
  bibtex_show={true},
  dimensions={true},
  pdf={26.pdf},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2023_Jesper,
  title={Style transfer for improved visualization of underdrawings and ghost paintings: An application to a work by {Vincent van Gogh}},
  author={Bourached, Anthony and Cann, George H and Griffiths, Ryan-Rhys and Eriksson, Jesper and Stork, David G},
  journal={Electronic Imaging},
  volume={35},
  pages={1--5},
  year={2023},
  publisher={Society for Imaging Science and Technology},
  bibtex_show={true},
  dimensions={true},
  pdf={27.pdf},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2024_Narayanan,
  title={Aviary: training language agents on challenging scientific tasks},
  author={Narayanan, Siddharth and Braza, James D and Griffiths, Ryan-Rhys and Ponnapati, Manu and Bou, Albert and Laurent, Jon and Kabeli, Ori and Wellawatte, Geemi and Cox, Sam and Rodriques, Samuel G and others},
  journal={arXiv preprint arXiv:2412.21154},
  year={2024},
  bibtex_show={true},
  dimensions={true},
  pdf={28.pdf},
  google_scholar_id={08ZZubdj9fEC}
}

@article{2024_Kell,
  title={{RealMedQA}: A pilot biomedical question answering dataset containing realistic clinical questions},
  author={Kell, Gregory and Roberts, Angus and Umansky, Serge and Khare, Yuti and Ahmed, Najma and Patel, Nikhil and Simela, Chloe and Coumbe, Jack and Rozario, Julian and Griffiths, Ryan-Rhys and others},
  journal={arXiv preprint arXiv:2408.08624},
  year={2024},
  bibtex_show={true},
  dimensions={true},
  pdf={29.pdf},
  google_scholar_id={08ZZubdj9fEC}
}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@article{2024_Tkachenko,
  title={Analyzing global utilization and missed opportunities in debt-for-nature swaps with generative {AI}},
  author={Tkachenko, Nataliya and Frieder, Simon and Griffiths, Ryan-Rhys and Nedopil, Christoph},
  journal={Frontiers in Artificial Intelligence},
  volume={7},
  pages={1167137},
  year={2024},
  bibtex_show={true},
  doi={10.3389/frai.2024.1167137},
  altmetrics={159123950},
  dimensions={true},
  pdf={30.pdf},
  publisher={Frontiers Media SA},
  google_scholar_id={dQ2og3OwTAUC},
  html={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1167137/full},
  url={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1167137/full}
}

@article{2017_Griffiths,
  title={A Theory of a Self-Assembling Electrovariable Smart Mirror},
  author={Griffiths, Ryan-Rhys},
  journal={arXiv preprint arXiv:1709.05494},
  bibtex_show={true},
  dimensions={true},
  pdf={31.pdf},
  year={2017}
}

@inproceedings{2024_Feng,
  title={Bayesian Optimization of High-dimensional Outputs with Human Feedback},
  author={Feng, Qing and Lin, Zhiyuan Jerry and Zhang, Yujia and Letham, Benjamin and Markovic-Voronov, Jelena and Griffiths, Ryan-Rhys and Frazier, Peter I and Bakshy, Eytan},
  booktitle={NeurIPS 2024 Workshop on Bayesian Decision-making and Uncertainty},
  bibtex_show={true},
  dimensions={true},
  pdf={32.pdf},
  url={https://openreview.net/forum?id=2fHwkHskpo},
  html={https://openreview.net/forum?id=2fHwkHskpo},
  year={2024},
  abstract={We consider optimizing the inputs to a black-box function that produces highdimensional outputs such as natural language, images, or robot trajectories. A
human decision maker (DM) has a utility function over these outputs. We may learn
about the DM’s utility by presenting a small set of outputs and asking which one
they prefer. We may learn about the black-box function by evaluating it at adaptively
chosen inputs. Given a limited number of such learning opportunities, our goal is
to find the input to the black box that maximizes the DM’s utility for the output
generated. Previously proposed methods for this and related tasks either do not
scale to high dimensional outputs or are statistically inefficient because they ignore
information in the outputs. Our proposed approach overcomes these challenges
using Bayesian optimization and a novel embedding of high-dimensional outputs
into a low-dimensional latent space customized for this task. This embedding is
designed to both minimize error when reconstructing high-dimensional outputs
and support accurate prediction of human judgments. We demonstrate that this
approach significantly improves over baseline methods.}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}
